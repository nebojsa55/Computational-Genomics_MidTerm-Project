{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-Example-notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebojsa55/Computational-Genomics_MidTerm-Project/blob/master/notebooks/ML_Example_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvBu3vZLwZDD"
      },
      "source": [
        "This notebook will provide complete insight in the training and testing process of [DREAM Birth challenge](https://www.synapse.org/#!Synapse:syn18380862wiki590485) Subchallenge 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4i3AN50qb3V"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Navigate to the folder cointaing our data\n",
        "%cd 'drive/MyDrive/ETF/Master/Computational-Genomics/Project/data'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnnfKMy2qhpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130753cd-22a9-4d4e-deef-13e9c5fc5eeb"
      },
      "source": [
        "# Verify the chosen folder\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anoSC1_v11_nokey.csv  anoSC2_v20_nokey.csv  eset_HuGene21ST.csv  HTA20_RMA.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "bVQ8pr4ZyHxI",
        "outputId": "b254e3bd-2a5c-4191-cc8e-5e85b3b02e93"
      },
      "source": [
        "anno = pd.read_csv('anoSC1_v11_nokey.csv', delimiter = ',', index_col = 0)\n",
        "anno.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GA</th>\n",
              "      <th>Batch</th>\n",
              "      <th>Set</th>\n",
              "      <th>Train</th>\n",
              "      <th>Platform</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SampleID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tarca_001_P1A01</th>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "      <td>PRB_HTA</td>\n",
              "      <td>1</td>\n",
              "      <td>HTA20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_013_P1B01</th>\n",
              "      <td>15.3</td>\n",
              "      <td>1</td>\n",
              "      <td>PRB_HTA</td>\n",
              "      <td>1</td>\n",
              "      <td>HTA20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_025_P1C01</th>\n",
              "      <td>21.7</td>\n",
              "      <td>1</td>\n",
              "      <td>PRB_HTA</td>\n",
              "      <td>1</td>\n",
              "      <td>HTA20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_037_P1D01</th>\n",
              "      <td>26.7</td>\n",
              "      <td>1</td>\n",
              "      <td>PRB_HTA</td>\n",
              "      <td>1</td>\n",
              "      <td>HTA20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_049_P1E01</th>\n",
              "      <td>31.3</td>\n",
              "      <td>1</td>\n",
              "      <td>PRB_HTA</td>\n",
              "      <td>1</td>\n",
              "      <td>HTA20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   GA  Batch      Set  Train Platform\n",
              "SampleID                                             \n",
              "Tarca_001_P1A01  11.0      1  PRB_HTA      1    HTA20\n",
              "Tarca_013_P1B01  15.3      1  PRB_HTA      1    HTA20\n",
              "Tarca_025_P1C01  21.7      1  PRB_HTA      1    HTA20\n",
              "Tarca_037_P1D01  26.7      1  PRB_HTA      1    HTA20\n",
              "Tarca_049_P1E01  31.3      1  PRB_HTA      1    HTA20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmKr4UcG5Ss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "01e55f83-2955-4d67-c780-6ca64fe86b80"
      },
      "source": [
        "HTA20_RMA = pd.read_csv('HTA20_RMA.csv', delimiter = ',', index_col = 0).transpose()\n",
        "HTA20_RMA.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_at</th>\n",
              "      <th>10_at</th>\n",
              "      <th>100_at</th>\n",
              "      <th>1000_at</th>\n",
              "      <th>10000_at</th>\n",
              "      <th>100009613_at</th>\n",
              "      <th>100009676_at</th>\n",
              "      <th>10001_at</th>\n",
              "      <th>10002_at</th>\n",
              "      <th>10003_at</th>\n",
              "      <th>100033411_at</th>\n",
              "      <th>100033413_at</th>\n",
              "      <th>100033414_at</th>\n",
              "      <th>100033418_at</th>\n",
              "      <th>100033420_at</th>\n",
              "      <th>100033422_at</th>\n",
              "      <th>100033423_at</th>\n",
              "      <th>100033424_at</th>\n",
              "      <th>100033425_at</th>\n",
              "      <th>100033426_at</th>\n",
              "      <th>100033427_at</th>\n",
              "      <th>100033428_at</th>\n",
              "      <th>100033430_at</th>\n",
              "      <th>100033431_at</th>\n",
              "      <th>100033432_at</th>\n",
              "      <th>100033433_at</th>\n",
              "      <th>100033434_at</th>\n",
              "      <th>100033435_at</th>\n",
              "      <th>100033436_at</th>\n",
              "      <th>100033437_at</th>\n",
              "      <th>100033438_at</th>\n",
              "      <th>100033439_at</th>\n",
              "      <th>100033440_at</th>\n",
              "      <th>100033441_at</th>\n",
              "      <th>100033444_at</th>\n",
              "      <th>100033445_at</th>\n",
              "      <th>100033447_at</th>\n",
              "      <th>100033451_at</th>\n",
              "      <th>100033453_at</th>\n",
              "      <th>100033603_at</th>\n",
              "      <th>...</th>\n",
              "      <th>9989_at</th>\n",
              "      <th>999_at</th>\n",
              "      <th>9990_at</th>\n",
              "      <th>9991_at</th>\n",
              "      <th>9992_at</th>\n",
              "      <th>9993_at</th>\n",
              "      <th>9994_at</th>\n",
              "      <th>9995_at</th>\n",
              "      <th>9997_at</th>\n",
              "      <th>AFFX-BkGr-GC03_at</th>\n",
              "      <th>AFFX-BkGr-GC04_at</th>\n",
              "      <th>AFFX-BkGr-GC05_at</th>\n",
              "      <th>AFFX-BkGr-GC06_at</th>\n",
              "      <th>AFFX-BkGr-GC07_at</th>\n",
              "      <th>AFFX-BkGr-GC08_at</th>\n",
              "      <th>AFFX-BkGr-GC09_at</th>\n",
              "      <th>AFFX-BkGr-GC10_at</th>\n",
              "      <th>AFFX-BkGr-GC11_at</th>\n",
              "      <th>AFFX-BkGr-GC12_at</th>\n",
              "      <th>AFFX-BkGr-GC13_at</th>\n",
              "      <th>AFFX-BkGr-GC14_at</th>\n",
              "      <th>AFFX-BkGr-GC15_at</th>\n",
              "      <th>AFFX-BkGr-GC16_at</th>\n",
              "      <th>AFFX-BkGr-GC17_at</th>\n",
              "      <th>AFFX-BkGr-GC18_at</th>\n",
              "      <th>AFFX-BkGr-GC19_at</th>\n",
              "      <th>AFFX-BkGr-GC20_at</th>\n",
              "      <th>AFFX-BkGr-GC21_at</th>\n",
              "      <th>AFFX-BkGr-GC22_at</th>\n",
              "      <th>AFFX-BkGr-GC23_at</th>\n",
              "      <th>AFFX-BkGr-GC24_at</th>\n",
              "      <th>AFFX-BkGr-GC25_at</th>\n",
              "      <th>AFFX-r2-Bs-dap-5_st</th>\n",
              "      <th>AFFX-r2-Bs-lys-5_st</th>\n",
              "      <th>AFFX-r2-Bs-phe-5_st</th>\n",
              "      <th>AFFX-r2-Bs-thr-5_st</th>\n",
              "      <th>AFFX-r2-Ec-bioB-5_at</th>\n",
              "      <th>AFFX-r2-Ec-bioC-5_at</th>\n",
              "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
              "      <th>AFFX-r2-P1-cre-5_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tarca_001_P1A01</th>\n",
              "      <td>6.062215</td>\n",
              "      <td>3.796484</td>\n",
              "      <td>5.849338</td>\n",
              "      <td>3.567779</td>\n",
              "      <td>6.166815</td>\n",
              "      <td>4.443027</td>\n",
              "      <td>5.836522</td>\n",
              "      <td>6.330018</td>\n",
              "      <td>4.922339</td>\n",
              "      <td>2.689344</td>\n",
              "      <td>2.745619</td>\n",
              "      <td>2.760609</td>\n",
              "      <td>3.794684</td>\n",
              "      <td>2.848183</td>\n",
              "      <td>2.812774</td>\n",
              "      <td>2.140590</td>\n",
              "      <td>2.692848</td>\n",
              "      <td>2.352924</td>\n",
              "      <td>2.484768</td>\n",
              "      <td>6.538760</td>\n",
              "      <td>9.544726</td>\n",
              "      <td>2.362534</td>\n",
              "      <td>2.406803</td>\n",
              "      <td>4.657512</td>\n",
              "      <td>3.047816</td>\n",
              "      <td>2.109620</td>\n",
              "      <td>5.771233</td>\n",
              "      <td>4.077138</td>\n",
              "      <td>3.123733</td>\n",
              "      <td>2.195346</td>\n",
              "      <td>2.975659</td>\n",
              "      <td>3.324574</td>\n",
              "      <td>2.430415</td>\n",
              "      <td>2.135031</td>\n",
              "      <td>2.073197</td>\n",
              "      <td>2.400044</td>\n",
              "      <td>2.235433</td>\n",
              "      <td>2.274116</td>\n",
              "      <td>2.261528</td>\n",
              "      <td>2.395431</td>\n",
              "      <td>...</td>\n",
              "      <td>8.815727</td>\n",
              "      <td>5.624144</td>\n",
              "      <td>9.769020</td>\n",
              "      <td>9.700440</td>\n",
              "      <td>3.771009</td>\n",
              "      <td>8.227688</td>\n",
              "      <td>5.992462</td>\n",
              "      <td>5.387680</td>\n",
              "      <td>7.220196</td>\n",
              "      <td>2.191452</td>\n",
              "      <td>2.111011</td>\n",
              "      <td>2.108250</td>\n",
              "      <td>2.120018</td>\n",
              "      <td>2.159772</td>\n",
              "      <td>2.215722</td>\n",
              "      <td>2.223840</td>\n",
              "      <td>2.286487</td>\n",
              "      <td>2.371125</td>\n",
              "      <td>2.499349</td>\n",
              "      <td>2.741896</td>\n",
              "      <td>3.064696</td>\n",
              "      <td>3.792943</td>\n",
              "      <td>4.401289</td>\n",
              "      <td>4.918235</td>\n",
              "      <td>5.631017</td>\n",
              "      <td>5.963709</td>\n",
              "      <td>6.412206</td>\n",
              "      <td>7.216170</td>\n",
              "      <td>7.863468</td>\n",
              "      <td>8.502729</td>\n",
              "      <td>8.786114</td>\n",
              "      <td>11.587051</td>\n",
              "      <td>8.342203</td>\n",
              "      <td>4.520028</td>\n",
              "      <td>5.636615</td>\n",
              "      <td>6.709797</td>\n",
              "      <td>8.972873</td>\n",
              "      <td>10.440245</td>\n",
              "      <td>12.101476</td>\n",
              "      <td>13.695705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_003_P1A03</th>\n",
              "      <td>6.125023</td>\n",
              "      <td>3.805305</td>\n",
              "      <td>6.191562</td>\n",
              "      <td>3.452524</td>\n",
              "      <td>5.678373</td>\n",
              "      <td>4.773199</td>\n",
              "      <td>6.143398</td>\n",
              "      <td>5.601745</td>\n",
              "      <td>4.711765</td>\n",
              "      <td>2.771010</td>\n",
              "      <td>3.263577</td>\n",
              "      <td>2.402899</td>\n",
              "      <td>3.346500</td>\n",
              "      <td>2.295464</td>\n",
              "      <td>2.752254</td>\n",
              "      <td>2.230644</td>\n",
              "      <td>2.808706</td>\n",
              "      <td>2.744754</td>\n",
              "      <td>2.392213</td>\n",
              "      <td>6.467364</td>\n",
              "      <td>8.983699</td>\n",
              "      <td>2.072872</td>\n",
              "      <td>2.145610</td>\n",
              "      <td>4.924804</td>\n",
              "      <td>2.951409</td>\n",
              "      <td>2.159747</td>\n",
              "      <td>5.714813</td>\n",
              "      <td>3.980073</td>\n",
              "      <td>2.873573</td>\n",
              "      <td>2.296149</td>\n",
              "      <td>2.765574</td>\n",
              "      <td>3.076334</td>\n",
              "      <td>1.960614</td>\n",
              "      <td>2.248927</td>\n",
              "      <td>2.554416</td>\n",
              "      <td>2.177165</td>\n",
              "      <td>2.065589</td>\n",
              "      <td>2.202918</td>\n",
              "      <td>2.091162</td>\n",
              "      <td>1.976425</td>\n",
              "      <td>...</td>\n",
              "      <td>8.226103</td>\n",
              "      <td>6.582291</td>\n",
              "      <td>9.389587</td>\n",
              "      <td>9.271577</td>\n",
              "      <td>3.838563</td>\n",
              "      <td>8.083417</td>\n",
              "      <td>5.826221</td>\n",
              "      <td>5.780958</td>\n",
              "      <td>7.440989</td>\n",
              "      <td>2.011836</td>\n",
              "      <td>2.053886</td>\n",
              "      <td>2.062657</td>\n",
              "      <td>2.106248</td>\n",
              "      <td>2.107264</td>\n",
              "      <td>2.171664</td>\n",
              "      <td>2.195808</td>\n",
              "      <td>2.285022</td>\n",
              "      <td>2.385383</td>\n",
              "      <td>2.570683</td>\n",
              "      <td>2.905709</td>\n",
              "      <td>3.323025</td>\n",
              "      <td>4.155433</td>\n",
              "      <td>4.921309</td>\n",
              "      <td>5.625932</td>\n",
              "      <td>6.350828</td>\n",
              "      <td>6.794233</td>\n",
              "      <td>7.217978</td>\n",
              "      <td>8.070590</td>\n",
              "      <td>8.642121</td>\n",
              "      <td>9.393085</td>\n",
              "      <td>9.594813</td>\n",
              "      <td>12.138090</td>\n",
              "      <td>9.010691</td>\n",
              "      <td>5.148384</td>\n",
              "      <td>6.723139</td>\n",
              "      <td>6.153199</td>\n",
              "      <td>9.376194</td>\n",
              "      <td>10.845176</td>\n",
              "      <td>12.370891</td>\n",
              "      <td>13.635522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_004_P1A04</th>\n",
              "      <td>5.875502</td>\n",
              "      <td>3.450245</td>\n",
              "      <td>6.550525</td>\n",
              "      <td>3.316134</td>\n",
              "      <td>6.185059</td>\n",
              "      <td>4.393488</td>\n",
              "      <td>5.898364</td>\n",
              "      <td>6.137984</td>\n",
              "      <td>4.628124</td>\n",
              "      <td>2.556756</td>\n",
              "      <td>2.707656</td>\n",
              "      <td>3.036456</td>\n",
              "      <td>4.299712</td>\n",
              "      <td>2.483257</td>\n",
              "      <td>3.513083</td>\n",
              "      <td>2.268800</td>\n",
              "      <td>3.034612</td>\n",
              "      <td>2.385361</td>\n",
              "      <td>2.288809</td>\n",
              "      <td>7.389350</td>\n",
              "      <td>10.039720</td>\n",
              "      <td>2.154480</td>\n",
              "      <td>2.025051</td>\n",
              "      <td>5.993964</td>\n",
              "      <td>2.810200</td>\n",
              "      <td>1.943169</td>\n",
              "      <td>6.154146</td>\n",
              "      <td>4.331164</td>\n",
              "      <td>2.710385</td>\n",
              "      <td>2.238039</td>\n",
              "      <td>2.833525</td>\n",
              "      <td>3.401957</td>\n",
              "      <td>2.044615</td>\n",
              "      <td>2.048938</td>\n",
              "      <td>1.958607</td>\n",
              "      <td>1.918034</td>\n",
              "      <td>1.815077</td>\n",
              "      <td>2.009749</td>\n",
              "      <td>2.109266</td>\n",
              "      <td>2.257260</td>\n",
              "      <td>...</td>\n",
              "      <td>8.454372</td>\n",
              "      <td>5.852143</td>\n",
              "      <td>9.431374</td>\n",
              "      <td>9.470850</td>\n",
              "      <td>3.568739</td>\n",
              "      <td>7.983239</td>\n",
              "      <td>6.175550</td>\n",
              "      <td>5.393079</td>\n",
              "      <td>7.331443</td>\n",
              "      <td>2.088989</td>\n",
              "      <td>2.003418</td>\n",
              "      <td>2.026268</td>\n",
              "      <td>2.039770</td>\n",
              "      <td>2.045315</td>\n",
              "      <td>2.089306</td>\n",
              "      <td>2.105618</td>\n",
              "      <td>2.184611</td>\n",
              "      <td>2.283092</td>\n",
              "      <td>2.430860</td>\n",
              "      <td>2.698857</td>\n",
              "      <td>3.048324</td>\n",
              "      <td>3.767554</td>\n",
              "      <td>4.423481</td>\n",
              "      <td>5.102220</td>\n",
              "      <td>5.843332</td>\n",
              "      <td>6.258922</td>\n",
              "      <td>6.762380</td>\n",
              "      <td>7.623269</td>\n",
              "      <td>8.280635</td>\n",
              "      <td>9.033983</td>\n",
              "      <td>9.294845</td>\n",
              "      <td>12.049271</td>\n",
              "      <td>8.555541</td>\n",
              "      <td>4.441900</td>\n",
              "      <td>6.016953</td>\n",
              "      <td>9.590764</td>\n",
              "      <td>8.843612</td>\n",
              "      <td>10.493416</td>\n",
              "      <td>12.295786</td>\n",
              "      <td>13.616688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_005_P1A05</th>\n",
              "      <td>6.126131</td>\n",
              "      <td>3.628411</td>\n",
              "      <td>6.421877</td>\n",
              "      <td>3.432451</td>\n",
              "      <td>5.633757</td>\n",
              "      <td>4.623783</td>\n",
              "      <td>6.019792</td>\n",
              "      <td>5.787502</td>\n",
              "      <td>4.796283</td>\n",
              "      <td>2.613415</td>\n",
              "      <td>2.807741</td>\n",
              "      <td>2.645834</td>\n",
              "      <td>3.810852</td>\n",
              "      <td>3.238697</td>\n",
              "      <td>2.784896</td>\n",
              "      <td>2.331521</td>\n",
              "      <td>2.756186</td>\n",
              "      <td>2.362922</td>\n",
              "      <td>2.314093</td>\n",
              "      <td>6.896619</td>\n",
              "      <td>9.346465</td>\n",
              "      <td>2.051147</td>\n",
              "      <td>2.134905</td>\n",
              "      <td>4.942601</td>\n",
              "      <td>3.305603</td>\n",
              "      <td>2.407998</td>\n",
              "      <td>5.454726</td>\n",
              "      <td>4.206752</td>\n",
              "      <td>2.410564</td>\n",
              "      <td>2.268998</td>\n",
              "      <td>2.669970</td>\n",
              "      <td>3.014598</td>\n",
              "      <td>2.033149</td>\n",
              "      <td>2.310311</td>\n",
              "      <td>2.188688</td>\n",
              "      <td>1.991138</td>\n",
              "      <td>2.243578</td>\n",
              "      <td>2.077085</td>\n",
              "      <td>2.033383</td>\n",
              "      <td>2.458295</td>\n",
              "      <td>...</td>\n",
              "      <td>8.606502</td>\n",
              "      <td>6.114320</td>\n",
              "      <td>9.544130</td>\n",
              "      <td>9.374321</td>\n",
              "      <td>3.691639</td>\n",
              "      <td>8.270554</td>\n",
              "      <td>5.635078</td>\n",
              "      <td>5.183500</td>\n",
              "      <td>7.298491</td>\n",
              "      <td>2.044670</td>\n",
              "      <td>2.094643</td>\n",
              "      <td>2.139602</td>\n",
              "      <td>2.094847</td>\n",
              "      <td>2.126440</td>\n",
              "      <td>2.150045</td>\n",
              "      <td>2.199919</td>\n",
              "      <td>2.325623</td>\n",
              "      <td>2.383102</td>\n",
              "      <td>2.567234</td>\n",
              "      <td>2.876098</td>\n",
              "      <td>3.277482</td>\n",
              "      <td>4.066424</td>\n",
              "      <td>4.859661</td>\n",
              "      <td>5.400951</td>\n",
              "      <td>6.173044</td>\n",
              "      <td>6.645898</td>\n",
              "      <td>7.140619</td>\n",
              "      <td>7.980902</td>\n",
              "      <td>8.647948</td>\n",
              "      <td>9.400945</td>\n",
              "      <td>9.694992</td>\n",
              "      <td>12.311885</td>\n",
              "      <td>9.164106</td>\n",
              "      <td>4.529299</td>\n",
              "      <td>6.990176</td>\n",
              "      <td>5.437926</td>\n",
              "      <td>9.191471</td>\n",
              "      <td>10.879879</td>\n",
              "      <td>12.249936</td>\n",
              "      <td>13.524328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tarca_006_P1A06</th>\n",
              "      <td>6.146466</td>\n",
              "      <td>3.446812</td>\n",
              "      <td>6.260962</td>\n",
              "      <td>3.477162</td>\n",
              "      <td>5.313198</td>\n",
              "      <td>4.422651</td>\n",
              "      <td>6.407699</td>\n",
              "      <td>5.830437</td>\n",
              "      <td>4.726488</td>\n",
              "      <td>2.631878</td>\n",
              "      <td>2.763387</td>\n",
              "      <td>3.105819</td>\n",
              "      <td>3.758044</td>\n",
              "      <td>2.501649</td>\n",
              "      <td>2.561260</td>\n",
              "      <td>2.455754</td>\n",
              "      <td>3.007438</td>\n",
              "      <td>2.332454</td>\n",
              "      <td>2.367595</td>\n",
              "      <td>6.941780</td>\n",
              "      <td>9.567956</td>\n",
              "      <td>2.472964</td>\n",
              "      <td>2.161994</td>\n",
              "      <td>5.286657</td>\n",
              "      <td>3.247169</td>\n",
              "      <td>2.878103</td>\n",
              "      <td>5.605735</td>\n",
              "      <td>4.337340</td>\n",
              "      <td>2.828053</td>\n",
              "      <td>2.455532</td>\n",
              "      <td>2.856074</td>\n",
              "      <td>3.206121</td>\n",
              "      <td>2.154353</td>\n",
              "      <td>1.970942</td>\n",
              "      <td>2.178542</td>\n",
              "      <td>2.094531</td>\n",
              "      <td>2.141441</td>\n",
              "      <td>2.075437</td>\n",
              "      <td>2.102256</td>\n",
              "      <td>2.141675</td>\n",
              "      <td>...</td>\n",
              "      <td>8.385291</td>\n",
              "      <td>6.566107</td>\n",
              "      <td>9.411351</td>\n",
              "      <td>9.267968</td>\n",
              "      <td>3.758960</td>\n",
              "      <td>8.012785</td>\n",
              "      <td>5.740465</td>\n",
              "      <td>5.434734</td>\n",
              "      <td>7.413392</td>\n",
              "      <td>2.170965</td>\n",
              "      <td>2.088567</td>\n",
              "      <td>2.095180</td>\n",
              "      <td>2.132475</td>\n",
              "      <td>2.139009</td>\n",
              "      <td>2.157587</td>\n",
              "      <td>2.199556</td>\n",
              "      <td>2.332073</td>\n",
              "      <td>2.395501</td>\n",
              "      <td>2.608228</td>\n",
              "      <td>2.871665</td>\n",
              "      <td>3.274047</td>\n",
              "      <td>4.047538</td>\n",
              "      <td>4.932088</td>\n",
              "      <td>5.494324</td>\n",
              "      <td>6.250512</td>\n",
              "      <td>6.722213</td>\n",
              "      <td>7.175260</td>\n",
              "      <td>8.003085</td>\n",
              "      <td>8.659736</td>\n",
              "      <td>9.397893</td>\n",
              "      <td>9.600712</td>\n",
              "      <td>12.173934</td>\n",
              "      <td>8.105479</td>\n",
              "      <td>4.989477</td>\n",
              "      <td>6.247265</td>\n",
              "      <td>7.550088</td>\n",
              "      <td>9.247768</td>\n",
              "      <td>10.754316</td>\n",
              "      <td>12.245458</td>\n",
              "      <td>13.509353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32830 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     1_at     10_at  ...  AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-5_at\n",
              "Tarca_001_P1A01  6.062215  3.796484  ...             12.101476            13.695705\n",
              "Tarca_003_P1A03  6.125023  3.805305  ...             12.370891            13.635522\n",
              "Tarca_004_P1A04  5.875502  3.450245  ...             12.295786            13.616688\n",
              "Tarca_005_P1A05  6.126131  3.628411  ...             12.249936            13.524328\n",
              "Tarca_006_P1A06  6.146466  3.446812  ...             12.245458            13.509353\n",
              "\n",
              "[5 rows x 32830 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT3s9eQiq6-h"
      },
      "source": [
        "## Missing data\n",
        "\n",
        "Unfortunately, all of the test data are missing **GA** (gastetion age) parameter, due to the nature od DREAM Pretem Challenge. In order to overcome this, we will use only the original training set for our model training and testing. 10% of data was used for testing (37 samples). 10-fold cross validation was performed in order to determine our ML model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TReRulx0Ls45",
        "outputId": "0692dc6c-34a8-41e2-8e16-54d5331b995b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "anno.loc[anno['Train'] == 1].shape[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQQutF5JVWEh"
      },
      "source": [
        "# Sync the X and y data by sorting the labels\n",
        "\n",
        "df1 = anno.sort_index()\n",
        "df2 = HTA20_RMA.sort_index()\n",
        "\n",
        "X = df2.iloc[np.array(np.logical_not(df1['GA'].isna())),:]\n",
        "y = df1.dropna().loc[:,['GA','Batch']]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcfV6Mt1qOHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb6b9b8-521a-4f11-995d-43e09b5dcb2c"
      },
      "source": [
        "# Check to see if the indexes are the same\n",
        "(X.index == y.index).all()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxsMMQUqOHt"
      },
      "source": [
        "## Standard scaling\n",
        "We will now perform the standard scaling of features from *one batch*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C_XPzQkqOHv"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "XX = np.zeros(X.shape)\n",
        "for i in [1,2,3,4,5,6,7,8,9,10,32]:\n",
        "    scale = StandardScaler()\n",
        "    indices = np.bool8(y['Batch'] == i)\n",
        "    Xtemp = X.iloc[indices,:]\n",
        "    scale.fit(Xtemp)\n",
        "    XX[indices,:] = scale.transform(Xtemp)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaB3DNRjqOHw"
      },
      "source": [
        "# delete batch column\n",
        "yy = y['GA']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-U8RW6io_Cz"
      },
      "source": [
        "## Regression\n",
        "\n",
        "In this section we will perform regression using a couple of well known regressors such as:\n",
        "* Randomn forrest regressor\n",
        "* nesto\n",
        "* nesto\n",
        "\n",
        "The main regression metric will be **RMSE** (Root mean square error), as it was used in DREAM Preterm challenge.\n",
        "\n",
        "### Random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGgvJuIoN0E2",
        "outputId": "6a441756-d5c7-476e-d0d6-cba0f05bfa54"
      },
      "source": [
        "# import necessary ML modules\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_of_splits = 10\n",
        "kf = KFold(n_splits = num_of_splits)\n",
        "regressor = RandomForestRegressor(n_estimators = 1000, n_jobs = -1, \n",
        "                                  random_state = 0)\n",
        "\n",
        "y_train_pred = []\n",
        "y_test_pred = []\n",
        "\n",
        "for train_index, test_index in tqdm(kf.split(XX), total = num_of_splits, unit = 'iteration'):\n",
        "\n",
        "  pca = PCA(n_components = 0.95, svd_solver = 'full')\n",
        "\n",
        "  X_train_std, X_test_std = XX[train_index,:], XX[test_index,:]\n",
        "  y_train, y_test = yy.iloc[train_index], yy.iloc[test_index]\n",
        "\n",
        "  X_train_pca = pca.fit_transform(X_train_std)\n",
        "  X_test_pca = pca.transform(X_test_std)\n",
        "  \n",
        "  regressor.fit(X_train_pca,y_train)\n",
        "  \n",
        "  y_train_pred.append(mean_squared_error(y_train,regressor.predict(X_train_pca), squared = False))\n",
        "  y_test_pred.append(mean_squared_error(y_test,regressor.predict(X_test_pca), squared = False))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [06:08<00:00, 36.89s/iteration]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpJBc5nxqOHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748a930f-f2e1-40ce-ef19-c58345e0f1ef"
      },
      "source": [
        "np.mean(y_train_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.722656997741857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKrdvoT9qOH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec7bf58-d393-4c74-c43f-7054bcfd47dc"
      },
      "source": [
        "np.mean(y_test_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.113025149662711"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgwoq05pq8u"
      },
      "source": [
        "### Model overfitting\n",
        "We can observe that our current RF model is overfiting. To overcome that, we will try to tune hyperparameters via crossvalidation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxOVWVMAYb4-",
        "outputId": "21898d33-88da-4c2c-c897-b21ee38b65a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 5)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 100, num = 11)]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [500, 875, 1250, 1625, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 19, 28, 37, 46, 55, 64, 73, 82, 91, 100], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFV9gMYXrrM3",
        "outputId": "37814cfb-1fe7-4440-81a7-53edadedab09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
        "                               n_iter = 50, cv = 10, verbose = 5, \n",
        "                               random_state = 42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(XX,yy)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4b87ebe31de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use the random grid to search for best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# First create the base model to tune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Random search of parameters, using 3 fold cross validation,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# search across 100 different combinations, and use all available cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6YLXnZNry4i",
        "outputId": "3305098f-ed28-4d39-af24-de0eab2615b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ea266b0743c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'rf_random' is not defined"
          ]
        }
      ]
    }
  ]
}